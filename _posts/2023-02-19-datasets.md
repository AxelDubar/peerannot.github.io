---
layout: post
title: Datasets
category: [doc]
tags: [datasets]
permalink: /datasets/
css:
  badge: true
  syntax: true
  custom: >-
    table { font-size: .95rem; margin-bottom: 1.5rem; }
    tr:nth-child(odd) { backgroud-color: #e3edf3; }
    th, td { padding: .5em; }
    .box { border: 1px solid #e3edf3; padding: 1rem; }
    .plaintext { color: mediumseagreen; }
excerpt: Models available in peerannot
featured: true
---

With `peerannot` one of our goal is to standardize crowdsourcing datasets formats. In order to do so, we need to remind users some notations.

## Notations

We remind that $y_i^{(j)}\in[K]$ is the label answered by the worker $w_j$ given the task $x_i$ (*e.g* an image).
The answered label is coded as a number representing the $K$ possible classes.

## Datasets structure

Each dataset is defined as:

  <pre><code class="lang-bash">dataset
      ├── train
      │     ├── class0
      │     │     ├─ task0-&lt;vote_index_0&gt;<span class="hljs-selector-class">.png</span>
      │     │     ├─ task1-&lt;vote_index_1&gt;<span class="hljs-selector-class">.png</span>
      │     │     ├─ ...
      │     │     └─ taskn0-&lt;vote_index_n0&gt;<span class="hljs-selector-class">.png</span>
      │     ├── class1
      │     ├── ...
      │     └── classK
      ├── val
      ├── test
      ├── dataset<span class="hljs-selector-class">.py</span>
      ├── metadata<span class="hljs-selector-class">.json</span>
      └── answers.json
  </code></pre>

  <p>The crowdsourced labels for each training task are contained in the <code>anwers.json</code> file. They are formatted
    as follows:</p>

  <pre><code class="lang-json">{
      0: {<span class="hljs-tag">&lt;<span class="hljs-name">worker_id</span>&gt;</span>: <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>, <span class="hljs-tag">&lt;<span class="hljs-name">another_worker_id</span>&gt;</span>: <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>},
      1: {<span class="hljs-tag">&lt;<span class="hljs-name">yet_another_worker_id</span>&gt;</span>: <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>,}
  }
  </code></pre>

  <p>Note that the task index in the <code>answers.json</code> file might not match the order of tasks in the
    <code>train</code> folder... Thence, each task&#39;s name contains the associated votes file index.
    The number of tasks in the <code>train</code> folder <strong>must</strong> match the number of entry keys in the
    <code>answers.json</code> file.</p>
  <p>The <code>metadata.json</code> file contains general information about the dataset. A minimal example would be:</p>

  <pre><code class="lang-json">{
      <span class="hljs-attr">"name"</span>: &lt;dataset&gt;,
      <span class="hljs-attr">"n_classes"</span>: K,
      <span class="hljs-attr">"n_workers"</span>: &lt;n_workers&gt;,
  }
  </code></pre>

In a dataset without tasks (for example when we only receive the crowdsourced labels), the `train`, `val` and `test` folders are omitted.
However, by doing so many learning strategies are not available.

## Download and install real datasets easily

  <p>The <code>dataset.py</code> is not mandatory but is here to facilitate the dataset&#39;s installation procedure. A
    minimal example:</p>

```python
class mydataset:
      def __init__(self):
          self.DIR = Path(__file__).parent.resolve()
          # download the data needed
          # ...

      def setfolders(self):
          print(f"Loading data folders at {self.DIR}")
          train_path = self.DIR / "train"
          test_path = self.DIR / "test"
          valid_path = self.DIR / "val"

          # Create train/val/test tasks with matching index
          # ...

          print("Created:")
          for set, path in zip(
              ("train", "val", "test"), [train_path, valid_path, test_path]
          ):
              print(f"- {set}: {path}")
          self.get_crowd_labels()
          print(f"Train crowd labels are in {self.DIR / 'answers.json'}")

      def get_crowd_labels(self):
          # create answers.json dictionnary in presented format
          # ...
          with open(self.DIR / "answers.json", "w") as answ:
              json.dump(dictionnary, answ, ensure_ascii=False, indent=3)
```

One can also instantiate in this installation file any necessary access or restrictions needed.

## Simulate datasets

The `simulate` module of `peerannot` allows creating simulated labels given a strategy.

### Examples

Examples of simulation strategies can be found in the following:
<ul>
  <!-- <li><a href="/datasets/simulate_confusions">Pairwise confusion with confusion matrices</a></li> -->
   <li><a href="/datasets/simulate_hammer_spammer">Hammer spammer</a></li>
  <li><a href="/datasets/simulate_discrete_difficulty">Discrete levels of difficulty</a></li>
</ul>
